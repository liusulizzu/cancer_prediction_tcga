{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pressing-transfer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import entropy\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "guided-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train(feature_name, dataset):\n",
    "    '''\n",
    "     feature_name : 特征名称\n",
    "     dataset: 训练集合的dataFrame的全集\n",
    "    '''\n",
    "    if  dataset is None:\n",
    "        return\n",
    "    if feature_name is None:\n",
    "        return\n",
    "    # 获取最后正样本和负样本两种数据的差异\n",
    "    #ax.set_title('{}患病和正常组的数据分布图'.format(feature_name))\n",
    "    #f, ax= plt.subplots()\n",
    "    g = sns.displot(dataset, x=feature_name, kind='kde', hue='label', fill=True, rug=True)\n",
    "    #g.set_axis_labels('{}'.format(feature_name))\n",
    "    #g.set_titles('ontrol group and disease group PDF',)\n",
    "    #g.set_ylabels(\"control group and disease group PDF\")\n",
    "    g.ax.set_title(u'{} disease group and control group PDF'.format(feature_name))\n",
    "    g.savefig(\"{}.png\".format(feature_name))\n",
    "    #sns.displot(disease_data,kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "attended-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_dist(dataset, feature_name, label, step):\n",
    "    # 左闭右开\n",
    "    if dataset is None:\n",
    "        return []\n",
    "    \n",
    "    min_val = min(dataset[feature_name])\n",
    "    max_val = max(dataset[feature_name]) \n",
    "    \n",
    "    #print('feature:{},min:{}, max:{}'.format(feature_name, min_val, max_val))\n",
    "    \n",
    "    #print('min:{}, max:{}'.format(min_val, max_val))\n",
    "    val = np.linspace(min_val, max_val, num=step+1)\n",
    "    val = val.tolist()\n",
    "    #print('val:{}'.format(val))\n",
    "    \n",
    "    dist=[]\n",
    "    deal_data = dataset.loc[dataset['label']==label]\n",
    "    if deal_data is None:\n",
    "        return []\n",
    "    sum_val = 0\n",
    "    for i in range (step):\n",
    "       # print('i:{},i+1:{}'.format(val[i], val[i+1]))\n",
    "        x = deal_data.loc[(deal_data[feature_name]>=val[i]) & (deal_data[feature_name]<val[i+1])]\n",
    "        sum_val = sum_val + len(x)\n",
    "        val_size = len(x)\n",
    "        dist.append(val_size)\n",
    "    \n",
    "    \n",
    "    for i, val in enumerate(dist):\n",
    "        if sum_val == 0:\n",
    "            break\n",
    "        dist[i] = dist[i]/sum_val\n",
    "        if dist[i] == 0:\n",
    "            dist[i] = 0.000001\n",
    "    return dist\n",
    "    \n",
    "\n",
    "def kl_divergence(feature_name, dataset):\n",
    "    '''\n",
    "    计算feature_name对应的kl散度\n",
    "    feature_name:特征名称\n",
    "    dataset 数据集合\n",
    "    面临一个问题，normal和disease两个数据长度不一致，需要对齐\n",
    "    就算长度对齐也不对，需要进行分桶，计算好分布\n",
    "    '''\n",
    "    neg = array_to_dist(dataset, feature_name, 0, 20)\n",
    "    pos = array_to_dist(dataset, feature_name, 1, 20)\n",
    "    \n",
    "    #print('neg:{},pos:{}'.format(neg, pos))\n",
    "    return entropy(neg, pos, base = 2)\n",
    "\n",
    "# 获取所有df的\n",
    "def get_all_kl_divergence(df):\n",
    "    features =[]\n",
    "    feature_kl = []\n",
    "    size = len(df.columns)\n",
    "    i = 0\n",
    "    for feature in df.columns:\n",
    "        if feature == 'label':\n",
    "            continue\n",
    "        features.append(feature)\n",
    "        feature_kl.append(kl_divergence(feature, df))\n",
    "        i = i + 1\n",
    "        print('process:{}'.format(i))\n",
    "    kl_feature_dataset = pd.DataFrame()\n",
    "    kl_feature_dataset['feature_name'] = features\n",
    "    kl_feature_dataset['kl_divergence'] = feature_kl\n",
    "    final = kl_feature_dataset.sort_values('kl_divergence', ascending=False)\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "df = pd.read_csv('final_train.csv', index_col=0)\n",
    "\n",
    "df.drop(['name'], axis=1, inplace = True)\n",
    "\n",
    "df3 = get_all_kl_divergence(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[19562]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.reset_index(drop=True)\n",
    "df4.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train('AGER', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['label'] = df['label'].apply(lambda x: int(not x))\n",
    "\n",
    "df.to_csv('final_train_v2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-repository",
   "metadata": {},
   "source": [
    "# 问题和改进点\n",
    "发现数据正负样本差别比较多，负样本比较少，正样本比较多，需要对正样本进行负采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_length(matrix, gene_len):\n",
    "    GFF3 = pd.read_csv(\n",
    "    filepath_or_buffer='Homo_sapiens.GRCh38.103.gtf', \n",
    "    sep='\\t', \n",
    "    header=None,\n",
    "    names=['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes'],\n",
    "    skiprows=[i for i in range(5)])\n",
    "\n",
    "    GFF3 = GFF3[GFF3['source'].notnull()]\n",
    "\n",
    "    return GFF3['attributes'].head()\n",
    "\n",
    "get_gen_length(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_gene(file):\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "\n",
    "def non_zero_count(ser):\n",
    "    val_np = ser.to_numpy()\n",
    "    #return np.max(val_np)\n",
    "    return np.percentile(val_np, 90)        \n",
    "    \n",
    "df = pd.read_csv('final_train_v2.csv', index_col=0)\n",
    "gene_name = []\n",
    "nonzero_count = []\n",
    "for index, row in df.iteritems():\n",
    "    if index == 'label':\n",
    "        continue\n",
    "   # print('index:{},row:{}'.format(index, row))\n",
    "    gene_name.append(index)\n",
    "    nonzero_count.append(row.aggregate(non_zero_count))\n",
    "df1 = pd.DataFrame({'gene':gene_name, 'nonzero_count':nonzero_count})\n",
    "df1.sort_values('nonzero_count', inplace = True)\n",
    "\n",
    "df2 = df1[df1['nonzero_count'] == 0]\n",
    "\n",
    "df.drop(df2['gene'], axis = 1, inplace = True)\n",
    "\n",
    "df.to_csv('final_train_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label'] == 0]['KREMEN1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label'] == 1]['KREMEN1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('final_train_v2.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['RBMY1J'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3['label'] == 1]['RBMY1J'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3['label'] == 0]['RBMY1J'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_train_v4.csv', index_col = 0)\n",
    "\n",
    "normal_df = df[df['label'] == 0]\n",
    "\n",
    "disease_df = df[df['label'] == 1].sample(n = 60)\n",
    "\n",
    "df1 = normal_df.append(disease_df)\n",
    "\n",
    "x = get_all_kl_divergence(df1)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "inner-founder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>kl_divergence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EZH2</td>\n",
       "      <td>16.572341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RS1</td>\n",
       "      <td>16.393907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STX11</td>\n",
       "      <td>16.268993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STIL</td>\n",
       "      <td>15.646141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPM6A</td>\n",
       "      <td>15.468277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>EFCC1</td>\n",
       "      <td>6.541349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>EBNA1BP2</td>\n",
       "      <td>6.534038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>TUFM</td>\n",
       "      <td>6.532677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>NUP35</td>\n",
       "      <td>6.531717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>NPNT</td>\n",
       "      <td>6.516254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_name  kl_divergence\n",
       "0           EZH2      16.572341\n",
       "1            RS1      16.393907\n",
       "2          STX11      16.268993\n",
       "3           STIL      15.646141\n",
       "4          GPM6A      15.468277\n",
       "..           ...            ...\n",
       "443        EFCC1       6.541349\n",
       "444     EBNA1BP2       6.534038\n",
       "445         TUFM       6.532677\n",
       "446        NUP35       6.531717\n",
       "447         NPNT       6.516254\n",
       "\n",
       "[448 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choosed_features = x[x['kl_divergence'] > 6.5].reset_index(drop = True)\n",
    "choosed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sudden-little",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'choosed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-611927a2df9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchoosed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'choosed' is not defined"
     ]
    }
   ],
   "source": [
    "choosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train('NPNT', df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "little-moses",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['EZH2label', 'RS1label', 'STX11label', 'STILlabel', 'GPM6Alabel',\\n       'SRPK1label', 'SFTPClabel', 'PAICSlabel', 'GALNT7label', 'AGERlabel',\\n       ...\\n       'MEFVlabel', 'LRRK2label', 'GRK5label', 'SEMA6Dlabel', 'ZNF280Clabel',\\n       'EFCC1label', 'EBNA1BP2label', 'TUFMlabel', 'NUP35label', 'NPNTlabel'],\\n      dtype='object', length=448)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-325cc2047adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#choosed_features['feature_name'].append('label')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoosed_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/bio_tf/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bio_tf/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bio_tf/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['EZH2label', 'RS1label', 'STX11label', 'STILlabel', 'GPM6Alabel',\\n       'SRPK1label', 'SFTPClabel', 'PAICSlabel', 'GALNT7label', 'AGERlabel',\\n       ...\\n       'MEFVlabel', 'LRRK2label', 'GRK5label', 'SEMA6Dlabel', 'ZNF280Clabel',\\n       'EFCC1label', 'EBNA1BP2label', 'TUFMlabel', 'NUP35label', 'NPNTlabel'],\\n      dtype='object', length=448)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#choosed_features['feature_name'].append('label')\n",
    "\n",
    "df_final = df[choosed_features['feature_name'] + ['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['label'] = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=20):\n",
    "  dataframe1 = dataframe.copy()\n",
    "  labels = dataframe1.pop('label')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe1), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe1))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds\n",
    "\n",
    "# 定义一个函数，输入数据，然后将列作为feature_column 然后构建lr模型来看哪个特征重要\n",
    "def train_model(data):\n",
    "    if data is None:\n",
    "        return None\n",
    "    if len(data.columns) == 0:\n",
    "        return None\n",
    "    feature_columns = []\n",
    "    for feature in data.columns:\n",
    "        if feature == 'label':\n",
    "            continue\n",
    "        feature_columns.append(tf.feature_column.numeric_column(feature))\n",
    "    \n",
    "    # 生成训练数据\n",
    "    batch_size=10\n",
    "    train, test = train_test_split(data, test_size=0.2)\n",
    "    train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "    test_ds = df_to_dataset(test, batch_size=batch_size)\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "          tf.keras.layers.DenseFeatures(feature_columns),\n",
    "          tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_regularizer = 'l1')\n",
    "    ])\n",
    "    model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])\n",
    "\n",
    "    model.fit(train_ds,\n",
    "          validation_data = test_ds,\n",
    "          epochs = 20)\n",
    "    auc = 0\n",
    "    for m in model.metrics:\n",
    "        if m.name == 'AUC':\n",
    "            auc = m.result().numpy()\n",
    "    return auc\n",
    "    \n",
    "\n",
    "df_t2 = shuffle(df_final)\n",
    "train_model(df_t2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-knitting",
   "metadata": {},
   "source": [
    "## 画箱线图看看效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t2.boxplot(column = 'CLEC3B', showmeans = True, notch = True, vert = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-headline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
